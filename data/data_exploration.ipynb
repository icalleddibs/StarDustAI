{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from collections import defaultdict\n",
    "import astropy\n",
    "from astropy.io import fits\n",
    "from astropy.table import Table, hstack\n",
    "from astropy.utils.metadata import MergeConflictWarning\n",
    "import glob\n",
    "import torch\n",
    "import random \n",
    "import os \n",
    "import subprocess\n",
    "import numpy as np\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.simplefilter('ignore', MergeConflictWarning)\n",
    "# List all FITS files\n",
    "# Get the repo root (assumes script is inside STARDUSTAI/)\n",
    "repo_root = subprocess.check_output([\"git\", \"rev-parse\", \"--show-toplevel\"], text=True).strip()\n",
    "base_dir = os.path.join(repo_root, \"data/full/\")\n",
    "file_paths = glob.glob(os.path.join(base_dir, \"*/*.fits\"))\n",
    "\n",
    "# If no FITS files are found, raise an error\n",
    "if not file_paths:\n",
    "    raise ValueError(\"No FITS files found in 'data/full/'\")\n",
    "\n",
    "# Shuffle the file paths\n",
    "random.shuffle(file_paths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom PyTorch dataset for lazy loading\n",
    "class FitsDataset(Dataset):\n",
    "    def __init__(self, file_paths):\n",
    "        self.file_paths = file_paths  # Store file paths\n",
    "        self.class_categories = ['STAR', 'GALAXY', 'QSO']\n",
    "        self.subclass_categories = ['nan', 'Starforming', 'Starburst', 'AGN', 'O', 'OB', 'B6', 'B9', 'A0', 'A0p', 'F2', 'F5', 'F9', 'G0', 'G2', 'G5', 'K1', 'K3', 'K5', 'K7', 'M0V', 'M2V', 'M1', 'M2', 'M3', 'M4', 'M5', 'M6', 'M7', 'M8', 'L0', 'L1', 'L2', 'L3', 'L4', 'L5', 'L5.5', 'L9', 'T2', 'Carbon', 'Carbon_lines', 'CarbonWD', 'CV', 'BROADLINE']\n",
    "        self.plate_quality_tags = {'bad': 0,  'marginal': 1, 'good': 2, 'nan': np.nan}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)  # Total number of files\n",
    "\n",
    "    def getitem(self, idx):\n",
    "        file_path = self.file_paths[idx]\n",
    "        \n",
    "        # Read FITS file as Astropy Table\n",
    "        dat1 = Table.read(file_path, format='fits', hdu=1)\n",
    "        dat1 = dat1['flux', 'loglam', 'ivar', 'model']\n",
    "        dat2 = Table.read(file_path, format='fits', hdu=2)\n",
    "        dat2 = dat2['PLATEQUALITY', 'PLATESN2', 'PLATE', 'TILE', 'MJD', 'FIBERID', 'CLASS', \"SUBCLASS\", 'Z', 'Z_ERR', 'SN_MEDIAN', 'SN_MEDIAN_ALL', 'ZWARNING' , 'RCHI2']\n",
    "        data = hstack([dat1, dat2])  # Merge HDUs\n",
    "        sn_median_values = np.vstack(data['SN_MEDIAN'])  # Shape: (4590, 5)\n",
    "\n",
    "        # Add new columns for each filter\n",
    "        data['SN_MEDIAN_UV'] = sn_median_values[:, 0]  # Ultraviolet\n",
    "        data['SN_MEDIAN_G'] = sn_median_values[:, 1]   # Green\n",
    "        data['SN_MEDIAN_R'] = sn_median_values[:, 2]   # Red\n",
    "        data['SN_MEDIAN_NIR'] = sn_median_values[:, 3] # Near-Infrared\n",
    "        data['SN_MEDIAN_IR'] = sn_median_values[:, 4]  # Infrared\n",
    "\n",
    "        # Remove the original SN_MEDIAN column if needed\n",
    "        data.remove_column('SN_MEDIAN')\n",
    "\n",
    "        # Convert Astropy Table to Pandas DataFrame\n",
    "        df = data.to_pandas()\n",
    "\n",
    "        # Map PLATEQUALITY to numerical values and fill NaNs with same value\n",
    "        df['PLATEQUALITY'] = df['PLATEQUALITY'].astype(str).map(self.plate_quality_tags)\n",
    "        first_value = df['PLATEQUALITY'].iloc[0]\n",
    "        df.fillna(value = {'PLATEQUALITY': first_value}, inplace=True)\n",
    "       \n",
    "\n",
    "        # one hot encode class\n",
    "        df['CLASS'] = df['CLASS'].astype(str)\n",
    "        class_label = df['CLASS'].values[0] \n",
    "        class_one_hot = np.zeros(len(self.class_categories))\n",
    "        class_one_hot[self.class_categories.index(class_label)] = 1\n",
    "\n",
    "        # one hot encode subclass\n",
    "        df['SUBCLASS'] = df['SUBCLASS'].astype(str)\n",
    "        subclass_label = df['SUBCLASS'].values[0]\n",
    "        if subclass_label not in self.subclass_categories:\n",
    "            subclass_label = 'nan'\n",
    "        subclass_one_hot = np.zeros(len(self.subclass_categories))\n",
    "        subclass_one_hot[self.subclass_categories.index(subclass_label)] = 1\n",
    "\n",
    "        # Drop class and subclass columns and keep everything else \n",
    "        features = df.drop(columns=['CLASS', 'SUBCLASS'])\n",
    "        features = features.fillna(0) \n",
    "        features = features.astype(np.float32) \n",
    "\n",
    "        features_tensor = torch.tensor(features.values, dtype=torch.float32)\n",
    "        class_label_tensor = torch.tensor(class_one_hot, dtype=torch.long)\n",
    "        subclass_label_tensor = torch.tensor(subclass_one_hot, dtype=torch.long)\n",
    "\n",
    "        return features_tensor, class_label_tensor, subclass_label_tensor  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([7.4049, 3.5555, 0.0350, 0.9253, 2.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4804, 1.5487, 2.5069,\n",
      "        2.4406, 1.6370])\n"
     ]
    }
   ],
   "source": [
    "dataset = FitsDataset(file_paths)\n",
    "print(dataset.getitem(3)[0][4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_stats(file_paths):\n",
    "    class_counts = defaultdict(int)\n",
    "    subclass_counts = defaultdict(int)\n",
    "    zwarning_zero = 0\n",
    "    total_objects = 0\n",
    "    problem_childs = 0\n",
    "    \n",
    "    for file_path in file_paths:\n",
    "        with fits.open(file_path) as hdul:\n",
    "            if len(hdul) <= 2:\n",
    "                print(f\"Skipping {file_path}: HDU 2 does not exist.\")\n",
    "                continue\n",
    "            hdu2 = hdul[2].data\n",
    "            main_class = str(hdu2['CLASS'][0]).strip().upper()\n",
    "            raw_subclass = str(hdu2['SUBCLASS'][0]).strip()\n",
    "            #if main_class == 'QSO':\n",
    "            #    print(raw_subclass)\n",
    "            \n",
    "            # Split subclass name to only include main title\n",
    "            clean_subclass = raw_subclass.split('(')[0].split('/')[0].strip()[:2]\n",
    "            if main_class == 'STAR' and len(clean_subclass) == 2:\n",
    "                subclass = clean_subclass\n",
    "            else:\n",
    "                subclass = raw_subclass if raw_subclass in SUBCLASS_CATEGORIES else 'nan'\n",
    "\n",
    "            class_counts[main_class] += 1\n",
    "            subclass_counts[subclass] += 1\n",
    "            \n",
    "            # ZWARNING\n",
    "            zwarnings = hdu2['ZWARNING']\n",
    "            zwarning_zero += (zwarnings == 0).sum()\n",
    "            total_objects += len(zwarnings)\n",
    "    \n",
    "    print(\"\\nClass Distribution:\")\n",
    "    for cls, count in class_counts.items():\n",
    "        print(f\"{cls}: {count} ({count/sum(class_counts.values()):.1%})\")\n",
    "\n",
    "    print(\"\\nSubclass Distribution:\")\n",
    "    for subcls, count in sorted(subclass_counts.items(), key=lambda x: -x[1]):\n",
    "        print(f\"{subcls}: {count}\")\n",
    "        \n",
    "    print(\"\\nSNR Distribution\")\n",
    "    \n",
    "    # Print ZWARNING\n",
    "    print(\"\\nZWARNING Distribution:\")\n",
    "    zwarning_nonzero = total_objects - zwarning_zero\n",
    "    print(f\"ZWARNING=0: {zwarning_zero} ({zwarning_zero/total_objects:.1%})\")\n",
    "    print(f\"ZWARNINGâ‰ 0: {zwarning_nonzero} ({zwarning_nonzero/total_objects:.1%})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: AstropyDeprecationWarning: The indent function is deprecated and may be removed in a future version.\n",
      "        Use textwrap.indent() instead. [astropy.io.fits.hdu.hdulist]\n",
      "WARNING: VerifyWarning: Error validating header for HDU #2 (note: Astropy uses zero-based indexing).\n",
      "    Header size is not multiple of 2880: 35070\n",
      "There may be extra bytes after the last HDU or the file is corrupted. [astropy.io.fits.hdu.hdulist]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping C:/Users/haris/Desktop/EngSci Y3S2/StarDust/StarDustAI\\data/full\\10227\\spec-10227-58224-0419.fits: HDU 2 does not exist.\n",
      "\n",
      "Class Distribution:\n",
      "QSO: 7785 (51.0%)\n",
      "STAR: 2135 (14.0%)\n",
      "GALAXY: 5351 (35.0%)\n",
      "\n",
      "Subclass Distribution:\n",
      "nan: 8501\n",
      "BROADLINE: 4303\n",
      "M5: 451\n",
      "F3: 290\n",
      "STARBURST: 251\n",
      "M4: 208\n",
      "WD: 123\n",
      "M6: 82\n",
      "F0: 81\n",
      "CV: 79\n",
      "M1: 79\n",
      "F8: 77\n",
      "STARFORMING: 71\n",
      "K3: 63\n",
      "G0: 60\n",
      "G8: 58\n",
      "K5: 55\n",
      "K0: 55\n",
      "Ld: 42\n",
      "A2: 34\n",
      "G4: 28\n",
      "F2: 26\n",
      "M3: 25\n",
      "F6: 22\n",
      "Ca: 18\n",
      "K1: 15\n",
      "A4: 13\n",
      "A1: 11\n",
      "B5: 11\n",
      "AGN: 10\n",
      "sd: 9\n",
      "K4: 9\n",
      "O8: 8\n",
      "B9: 8\n",
      "G9: 8\n",
      "A9: 8\n",
      "G5: 8\n",
      "B8: 7\n",
      "G1: 6\n",
      "B3: 5\n",
      "B2: 5\n",
      "M0: 5\n",
      "A5: 4\n",
      "A3: 4\n",
      "O9: 4\n",
      "F9: 3\n",
      "G3: 3\n",
      "M2: 3\n",
      "M7: 3\n",
      "K2: 3\n",
      "B0: 3\n",
      "A8: 3\n",
      "M8: 2\n",
      "B7: 2\n",
      "F5: 2\n",
      "B1: 1\n",
      "Am: 1\n",
      "A0: 1\n",
      "B6: 1\n",
      "\n",
      "ZWARNING Distribution:\n",
      "ZWARNING=0: 11661 (76.4%)\n",
      "ZWARNINGâ‰ 0: 3610 (23.6%)\n"
     ]
    }
   ],
   "source": [
    "SUBCLASS_CATEGORIES = ['nan', 'STARFORMING', 'STARBURST', 'AGN', 'O', 'OB', 'B6', 'B9', 'A0', 'A0p', 'F2', 'F5', 'F9', 'G0', 'G2', 'G5', 'K1', 'K3', 'K5', 'K7', 'M0V', 'M2V', 'M1', 'M2', 'M3', 'M4', 'M5', 'M6', 'M7', 'M8', 'L0', 'L1', 'L2', 'L3', 'L4', 'L5', 'L5.5', 'L9', 'T2', 'Carbon', 'Carbon_lines', 'CarbonWD', 'CV', 'BROADLINE']\n",
    "data_stats(file_paths)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
