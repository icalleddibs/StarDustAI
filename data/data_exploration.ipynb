{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from collections import defaultdict\n",
    "import astropy\n",
    "from astropy.io import fits\n",
    "from astropy.table import Table, hstack\n",
    "from astropy.utils.metadata import MergeConflictWarning\n",
    "import glob\n",
    "import torch\n",
    "import random \n",
    "import os \n",
    "import subprocess\n",
    "import numpy as np\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.simplefilter('ignore', MergeConflictWarning)\n",
    "# List all FITS files\n",
    "# Get the repo root (assumes script is inside STARDUSTAI/)\n",
    "repo_root = subprocess.check_output([\"git\", \"rev-parse\", \"--show-toplevel\"], text=True).strip()\n",
    "base_dir = os.path.join(repo_root, \"data/full\")\n",
    "file_paths = glob.glob(os.path.join(base_dir, \"*/*.fits\"))\n",
    "\n",
    "# If no FITS files are found, raise an error\n",
    "if not file_paths:\n",
    "    raise ValueError(\"No FITS files found in 'data/full/'\")\n",
    "\n",
    "# Shuffle the file paths\n",
    "random.shuffle(file_paths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom PyTorch dataset for lazy loading\n",
    "class FitsDataset(Dataset):\n",
    "    def __init__(self, file_paths):\n",
    "        self.file_paths = file_paths  # Store file paths\n",
    "        self.class_categories = ['STAR', 'GALAXY', 'QSO']\n",
    "        self.subclass_categories = ['nan', 'Starforming', 'Starburst', 'AGN', 'O', 'OB', 'B6', 'B9', 'A0', 'A0p', 'F2', 'F5', 'F9', 'G0', 'G2', 'G5', 'K1', 'K3', 'K5', 'K7', 'M0V', 'M2V', 'M1', 'M2', 'M3', 'M4', 'M5', 'M6', 'M7', 'M8', 'L0', 'L1', 'L2', 'L3', 'L4', 'L5', 'L5.5', 'L9', 'T2', 'Carbon', 'Carbon_lines', 'CarbonWD', 'CV', 'BROADLINE']\n",
    "        self.plate_quality_tags = {'bad': 0,  'marginal': 1, 'good': 2, 'nan': np.nan}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)  # Total number of files\n",
    "\n",
    "    def getitem(self, idx):\n",
    "        file_path = self.file_paths[idx]\n",
    "        \n",
    "        # Read FITS file as Astropy Table\n",
    "        dat1 = Table.read(file_path, format='fits', hdu=1)\n",
    "        dat1 = dat1['flux', 'loglam', 'ivar', 'model']\n",
    "        dat2 = Table.read(file_path, format='fits', hdu=2)\n",
    "        dat2 = dat2['PLATEQUALITY', 'PLATESN2', 'PLATE', 'TILE', 'MJD', 'FIBERID', 'CLASS', \"SUBCLASS\", 'Z', 'Z_ERR', 'SN_MEDIAN', 'SN_MEDIAN_ALL', 'ZWARNING' , 'RCHI2']\n",
    "        data = hstack([dat1, dat2])  # Merge HDUs\n",
    "        sn_median_values = np.vstack(data['SN_MEDIAN'])  # Shape: (4590, 5)\n",
    "\n",
    "        # Add new columns for each filter\n",
    "        data['SN_MEDIAN_UV'] = sn_median_values[:, 0]  # Ultraviolet\n",
    "        data['SN_MEDIAN_G'] = sn_median_values[:, 1]   # Green\n",
    "        data['SN_MEDIAN_R'] = sn_median_values[:, 2]   # Red\n",
    "        data['SN_MEDIAN_NIR'] = sn_median_values[:, 3] # Near-Infrared\n",
    "        data['SN_MEDIAN_IR'] = sn_median_values[:, 4]  # Infrared\n",
    "\n",
    "        # Remove the original SN_MEDIAN column if needed\n",
    "        data.remove_column('SN_MEDIAN')\n",
    "\n",
    "        # Convert Astropy Table to Pandas DataFrame\n",
    "        df = data.to_pandas()\n",
    "\n",
    "        # Map PLATEQUALITY to numerical values and fill NaNs with same value\n",
    "        df['PLATEQUALITY'] = df['PLATEQUALITY'].astype(str).map(self.plate_quality_tags)\n",
    "        first_value = df['PLATEQUALITY'].iloc[0]\n",
    "        df.fillna(value = {'PLATEQUALITY': first_value}, inplace=True)\n",
    "       \n",
    "\n",
    "        # one hot encode class\n",
    "        df['CLASS'] = df['CLASS'].astype(str)\n",
    "        class_label = df['CLASS'].values[0] \n",
    "        class_one_hot = np.zeros(len(self.class_categories))\n",
    "        class_one_hot[self.class_categories.index(class_label)] = 1\n",
    "\n",
    "        # one hot encode subclass\n",
    "        df['SUBCLASS'] = df['SUBCLASS'].astype(str)\n",
    "        subclass_label = df['SUBCLASS'].values[0]\n",
    "        if subclass_label not in self.subclass_categories:\n",
    "            subclass_label = 'nan'\n",
    "        subclass_one_hot = np.zeros(len(self.subclass_categories))\n",
    "        subclass_one_hot[self.subclass_categories.index(subclass_label)] = 1\n",
    "\n",
    "        # Drop class and subclass columns and keep everything else \n",
    "        features = df.drop(columns=['CLASS', 'SUBCLASS'])\n",
    "        features = features.fillna(0) \n",
    "        features = features.astype(np.float32) \n",
    "\n",
    "        features_tensor = torch.tensor(features.values, dtype=torch.float32)\n",
    "        class_label_tensor = torch.tensor(class_one_hot, dtype=torch.long)\n",
    "        subclass_label_tensor = torch.tensor(subclass_one_hot, dtype=torch.long)\n",
    "\n",
    "        return features_tensor, class_label_tensor, subclass_label_tensor  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([6.2459, 3.5556, 0.0755, 0.0634, 2.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0713, 1.1632, 2.5006,\n",
      "        4.2890, 3.9944])\n"
     ]
    }
   ],
   "source": [
    "dataset = FitsDataset(file_paths)\n",
    "print(dataset.getitem(3)[0][4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_stats(file_paths):\n",
    "    class_counts = defaultdict(int)\n",
    "    subclass_counts = defaultdict(int)\n",
    "    zwarning_zero = 0\n",
    "    total_objects = 0\n",
    "    problem_childs = 0\n",
    "    \n",
    "    for file_path in file_paths:\n",
    "        with fits.open(file_path) as hdul:\n",
    "            hdu2 = hdul[2].data\n",
    "            main_class = str(hdu2['CLASS'][0]).strip().upper()\n",
    "            raw_subclass = str(hdu2['SUBCLASS'][0]).strip()\n",
    "            #if main_class == 'QSO':\n",
    "            #    print(raw_subclass)\n",
    "            \n",
    "            # Split subclass name to only include main title\n",
    "            clean_subclass = raw_subclass.split('(')[0].split('/')[0].strip()[:2]\n",
    "            if main_class == 'STAR' and len(clean_subclass) == 2:\n",
    "                subclass = clean_subclass\n",
    "            else:\n",
    "                subclass = raw_subclass if raw_subclass in SUBCLASS_CATEGORIES else 'nan'\n",
    "\n",
    "            class_counts[main_class] += 1\n",
    "            subclass_counts[subclass] += 1\n",
    "            \n",
    "            # ZWARNING\n",
    "            zwarnings = hdu2['ZWARNING']\n",
    "            zwarning_zero += (zwarnings == 0).sum()\n",
    "            total_objects += len(zwarnings)\n",
    "    \n",
    "    print(\"\\nClass Distribution:\")\n",
    "    for cls, count in class_counts.items():\n",
    "        print(f\"{cls}: {count} ({count/sum(class_counts.values()):.1%})\")\n",
    "\n",
    "    print(\"\\nSubclass Distribution:\")\n",
    "    for subcls, count in sorted(subclass_counts.items(), key=lambda x: -x[1]):\n",
    "        print(f\"{subcls}: {count}\")\n",
    "    \n",
    "    # Print ZWARNING\n",
    "    print(\"\\nZWARNING Distribution:\")\n",
    "    zwarning_nonzero = total_objects - zwarning_zero\n",
    "    print(f\"ZWARNING=0: {zwarning_zero} ({zwarning_zero/total_objects:.1%})\")\n",
    "    print(f\"ZWARNING≠0: {zwarning_nonzero} ({zwarning_nonzero/total_objects:.1%})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class Distribution:\n",
      "QSO: 126 (43.6%)\n",
      "GALAXY: 114 (39.4%)\n",
      "STAR: 49 (17.0%)\n",
      "\n",
      "Subclass Distribution:\n",
      "nan: 164\n",
      "BROADLINE: 71\n",
      "F3: 8\n",
      "M4: 8\n",
      "M1: 5\n",
      "F0: 5\n",
      "M5: 4\n",
      "STARBURST: 3\n",
      "K3: 3\n",
      "STARFORMING: 2\n",
      "CV: 2\n",
      "K5: 2\n",
      "G8: 2\n",
      "F6: 2\n",
      "Ld: 2\n",
      "B3: 1\n",
      "B5: 1\n",
      "WD: 1\n",
      "F2: 1\n",
      "G4: 1\n",
      "F8: 1\n",
      "\n",
      "ZWARNING Distribution:\n",
      "ZWARNING=0: 217 (75.1%)\n",
      "ZWARNING≠0: 72 (24.9%)\n"
     ]
    }
   ],
   "source": [
    "SUBCLASS_CATEGORIES = ['nan', 'STARFORMING', 'STARBURST', 'AGN', 'O', 'OB', 'B6', 'B9', 'A0', 'A0p', 'F2', 'F5', 'F9', 'G0', 'G2', 'G5', 'K1', 'K3', 'K5', 'K7', 'M0V', 'M2V', 'M1', 'M2', 'M3', 'M4', 'M5', 'M6', 'M7', 'M8', 'L0', 'L1', 'L2', 'L3', 'L4', 'L5', 'L5.5', 'L9', 'T2', 'Carbon', 'Carbon_lines', 'CarbonWD', 'CV', 'BROADLINE']\n",
    "data_stats(file_paths)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
