{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import random \n",
    "import os \n",
    "import subprocess\n",
    "from collections import defaultdict\n",
    "\n",
    "# Astropy Loading\n",
    "import astropy\n",
    "from astropy.io import fits\n",
    "from astropy.table import Table, hstack\n",
    "from astropy.utils.metadata import MergeConflictWarning\n",
    "\n",
    "# Scientific Python\n",
    "import numpy as np\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.simplefilter('ignore', MergeConflictWarning)\n",
    "# List all FITS files\n",
    "# Get the repo root (assumes script is inside STARDUSTAI/)\n",
    "repo_root = subprocess.check_output([\"git\", \"rev-parse\", \"--show-toplevel\"], text=True).strip()\n",
    "base_dir = os.path.join(repo_root, \"data/full/\")\n",
    "file_paths = glob.glob(os.path.join(base_dir, \"*/*.fits\"))\n",
    "\n",
    "# If no FITS files are found, raise an error\n",
    "if not file_paths:\n",
    "    raise ValueError(\"No FITS files found in 'data/full/'\")\n",
    "\n",
    "# Shuffle the file paths\n",
    "random.shuffle(file_paths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom PyTorch dataset for loading\n",
    "class FitsDataset(Dataset):\n",
    "    def __init__(self, file_paths):\n",
    "        self.file_paths = file_paths  # Store file paths\n",
    "        self.class_categories = ['STAR', 'GALAXY', 'QSO']\n",
    "        self.subclass_categories = ['nan', 'Starforming', 'Starburst', 'AGN', 'O', 'OB', 'B6', 'B9', 'A0', 'A0p', 'F2', 'F5', 'F9', 'G0', 'G2', 'G5', 'K1', 'K3', 'K5', 'K7', 'M0V', 'M2V', 'M1', 'M2', 'M3', 'M4', 'M5', 'M6', 'M7', 'M8', 'L0', 'L1', 'L2', 'L3', 'L4', 'L5', 'L5.5', 'L9', 'T2', 'Carbon', 'Carbon_lines', 'CarbonWD', 'CV', 'BROADLINE']\n",
    "        self.plate_quality_tags = {'bad': 0,  'marginal': 1, 'good': 2, 'nan': np.nan}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)  # Total number of files\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_path = self.file_paths[idx]\n",
    "        \n",
    "        # Read FITS file as Astropy Table\n",
    "        dat1 = Table.read(file_path, format='fits', hdu=1)\n",
    "        dat1 = dat1['flux', 'loglam', 'ivar', 'model']\n",
    "        dat2 = Table.read(file_path, format='fits', hdu=2)\n",
    "        dat2 = dat2['PLATEQUALITY', 'PLATESN2', 'PLATE', 'TILE', 'MJD', 'FIBERID', 'CLASS', \"SUBCLASS\", 'Z', 'Z_ERR', 'SN_MEDIAN', 'SN_MEDIAN_ALL', 'ZWARNING' , 'RCHI2']\n",
    "        data = hstack([dat1, dat2])  # Merge HDUs\n",
    "        sn_median_values = np.vstack(data['SN_MEDIAN'])  # Shape: (4590, 5)\n",
    "\n",
    "        # Add new columns for each filter\n",
    "        data['SN_MEDIAN_UV'] = sn_median_values[:, 0]  # Ultraviolet\n",
    "        data['SN_MEDIAN_G'] = sn_median_values[:, 1]   # Green\n",
    "        data['SN_MEDIAN_R'] = sn_median_values[:, 2]   # Red\n",
    "        data['SN_MEDIAN_NIR'] = sn_median_values[:, 3] # Near-Infrared\n",
    "        data['SN_MEDIAN_IR'] = sn_median_values[:, 4]  # Infrared\n",
    "\n",
    "        # Remove the original SN_MEDIAN column if needed\n",
    "        data.remove_column('SN_MEDIAN')\n",
    "\n",
    "        # Convert Astropy Table to Pandas DataFrame\n",
    "        df = data.to_pandas()\n",
    "\n",
    "        # Map PLATEQUALITY to numerical values and fill NaNs with same value\n",
    "        df['PLATEQUALITY'] = df['PLATEQUALITY'].astype(str).map(self.plate_quality_tags)\n",
    "        first_value = df['PLATEQUALITY'].iloc[0]\n",
    "        df.fillna(value = {'PLATEQUALITY': first_value}, inplace=True)\n",
    "       \n",
    "\n",
    "        # one hot encode class\n",
    "        df['CLASS'] = df['CLASS'].astype(str)\n",
    "        class_label = df['CLASS'].values[0] \n",
    "        class_one_hot = np.zeros(len(self.class_categories))\n",
    "        class_one_hot[self.class_categories.index(class_label)] = 1\n",
    "\n",
    "        # one hot encode subclass\n",
    "        df['SUBCLASS'] = df['SUBCLASS'].astype(str)\n",
    "        subclass_label = df['SUBCLASS'].values[0]\n",
    "        if subclass_label not in self.subclass_categories:\n",
    "            subclass_label = 'nan'\n",
    "        subclass_one_hot = np.zeros(len(self.subclass_categories))\n",
    "        subclass_one_hot[self.subclass_categories.index(subclass_label)] = 1\n",
    "\n",
    "        # Drop class and subclass columns and keep everything else \n",
    "        features = df.drop(columns=['CLASS', 'SUBCLASS'])\n",
    "        features = features.fillna(0) \n",
    "        features = features.astype(np.float32) \n",
    "\n",
    "        features_tensor = torch.tensor(features.values, dtype=torch.float32)\n",
    "        class_label_tensor = torch.tensor(class_one_hot, dtype=torch.long)\n",
    "        subclass_label_tensor = torch.tensor(subclass_one_hot, dtype=torch.long)\n",
    "\n",
    "        return features_tensor, class_label_tensor, subclass_label_tensor  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = FitsDataset(file_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_stats(file_paths):\n",
    "    \"\"\"\n",
    "    Process a list of FITS files and print statistics related to class \n",
    "    distribution, subclass distribution, and ZWARNING.\n",
    "\n",
    "    Args:\n",
    "        file_paths (list of str): A list of file paths to the FITS files.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the redshifts, sn_median_all, and \n",
    "              zwarning class counts.\n",
    "    \"\"\"\n",
    "    class_counts = defaultdict(int)\n",
    "    subclass_counts = defaultdict(int)\n",
    "    zwarning_zero = 0\n",
    "    total_objects = 0\n",
    "    \n",
    "    # New containers for additional analysis\n",
    "    zwarning_class_counts = defaultdict(int)\n",
    "    redshifts = defaultdict(list)\n",
    "    sn_median_all = defaultdict(list)\n",
    "\n",
    "    for file_path in file_paths:\n",
    "        with fits.open(file_path) as hdul:\n",
    "            if len(hdul) <= 2:\n",
    "                print(f\"Skipping {file_path}: HDU 2 does not exist.\")\n",
    "                continue\n",
    "            hdu2 = hdul[2].data\n",
    "            \n",
    "            # Original processing (first object)\n",
    "            main_class = str(hdu2['CLASS'][0]).strip().upper()\n",
    "            raw_subclass = str(hdu2['SUBCLASS'][0]).strip()\n",
    "            \n",
    "            clean_subclass = raw_subclass.split('(')[0].split('/')[0].strip()[:2]\n",
    "            if main_class == 'STAR' and len(clean_subclass) == 2:\n",
    "                subclass = clean_subclass\n",
    "            else:\n",
    "                subclass = raw_subclass if raw_subclass in SUBCLASS_CATEGORIES else 'nan'\n",
    "\n",
    "            class_counts[main_class] += 1\n",
    "            subclass_counts[subclass] += 1\n",
    "            \n",
    "            # New processing (all objects)\n",
    "            for obj in hdu2:\n",
    "                total_objects += 1\n",
    "                cls = str(obj['CLASS']).strip().upper()\n",
    "                \n",
    "                # Extract ZWARNING and SN_MEDIAN_ALL values safely\n",
    "                zwarn = obj['ZWARNING']\n",
    "                sn_median_all_value = float(obj['SN_MEDIAN_ALL'])\n",
    "                \n",
    "                # Collect data for histograms\n",
    "                redshifts[cls].append(float(obj['Z']))\n",
    "                sn_median_all[cls].append(sn_median_all_value)\n",
    "                \n",
    "                # Track ZWARNING class distribution\n",
    "                if zwarn != 0:\n",
    "                    zwarning_class_counts[cls] += 1\n",
    "                else:\n",
    "                    zwarning_zero += 1\n",
    "\n",
    "    # Original print statements\n",
    "    print(\"\\nClass Distribution:\")\n",
    "    for cls, count in class_counts.items():\n",
    "        print(f\"{cls}: {count} ({count/sum(class_counts.values()):.1%})\")\n",
    "\n",
    "    print(\"\\nSubclass Distribution:\")\n",
    "    for subcls, count in sorted(subclass_counts.items(), key=lambda x: -x[1]):\n",
    "        print(f\"{subcls}: {count}\")\n",
    "    \n",
    "    print(\"\\nZWARNING Distribution:\")\n",
    "    zwarning_nonzero = total_objects - zwarning_zero\n",
    "    print(f\"ZWARNING=0: {zwarning_zero} ({zwarning_zero/total_objects:.1%})\")\n",
    "    print(f\"ZWARNINGâ‰ 0: {zwarning_nonzero} ({zwarning_nonzero/total_objects:.1%})\")\n",
    "\n",
    "    # New: ZWARNING class breakdown\n",
    "    print(\"\\nNon-zero ZWARNING Class Distribution:\")\n",
    "    for cls, count in zwarning_class_counts.items():\n",
    "        print(f\"{cls}: {count} ({count/zwarning_nonzero:.1%})\")\n",
    "\n",
    "    # Return data for plotting\n",
    "    return {\n",
    "        'redshifts': dict(redshifts),\n",
    "        'sn_median_all': dict(sn_median_all),\n",
    "        'zwarning_class_counts': dict(zwarning_class_counts)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBCLASS_CATEGORIES = ['nan', 'STARFORMING', 'STARBURST', 'AGN', 'O', 'OB', 'B6', 'B9', 'A0', 'A0p', 'F2', 'F5', 'F9', 'G0', 'G2', 'G5', 'K1', 'K3', 'K5', 'K7', 'M0V', 'M2V', 'M1', 'M2', 'M3', 'M4', 'M5', 'M6', 'M7', 'M8', 'L0', 'L1', 'L2', 'L3', 'L4', 'L5', 'L5.5', 'L9', 'T2', 'Carbon', 'Carbon_lines', 'CarbonWD', 'CV', 'BROADLINE']\n",
    "analysis_data = data_stats(file_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_histogram(vals, bins=30):\n",
    "    \"\"\"\n",
    "    Plots a stacked histogram of the redshift / signal-to-noise ratio (SNR) distribution for different classes.\n",
    "\n",
    "    Args:\n",
    "        vals (dict): A dictionary where the keys are class names (strings) and the values are lists of \n",
    "                           redshift / signal-to-noise ratio (SNR) values for each class.\n",
    "        bins (int, optional): The number of bins to use in the histogram (default is 30).\n",
    "\n",
    "    Returns:\n",
    "        None: This function generates and displays the plot, but does not return any value.\n",
    "    \"\"\"\n",
    "    # Prepare data and labels\n",
    "    classes = list(vals.keys())\n",
    "    data = [vals[cls] for cls in classes if len(vals[cls]) > 0]\n",
    "    \n",
    "    # Define colors for each class\n",
    "    colors = ['blue', 'orange', 'green']\n",
    "    \n",
    "    # Create stacked histogram\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(data, bins=bins, stacked=True, label=classes, color=colors, edgecolor=\"black\", alpha=0.7)\n",
    "    \n",
    "    # Add labels and title\n",
    "    plt.title('Signal-To-Noise Ratio Distribution by Class', fontsize=14)\n",
    "    plt.xlabel('Signal to Noise Ratio', fontsize=12)\n",
    "    plt.ylabel('Count', fontsize=12)\n",
    "    plt.legend(title=\"Classes\", fontsize=10)\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "redshift_data = analysis_data['sn_median_all'] \n",
    "plot_histogram(redshift_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
